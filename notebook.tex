
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{MY\_Analyzing SV tweets through NLP-Copy1}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Sentiment analysis of tweets from top 26 Silicon Valley (SV)
influencers.}\label{sentiment-analysis-of-tweets-from-top-26-silicon-valley-sv-influencers.}

    In this part i will try to make some analysis of earlier created
dataset. Will use different methods of NLP, mostly NLTK but also Gensim.
The full list of used packages is described in window below.

\textbf{Data}: time-series data of tweets from a curated list of SV most
followed people

\textbf{Dataset}: dataset which i use was manually extracted from the
Twitter API into .CSV (as you can see in the first notebook i have
sended)

    \subsection{Preparing data science
packages}\label{preparing-data-science-packages}

This project was written in Python language and libraries and packages
used here are chosen on this base.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}316}]:} \PY{c+c1}{\PYZsh{} Data science toolbox:}
          \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}  \PY{c+c1}{\PYZsh{} it let me to put collected and analysing information into dataframe object for data manipulation}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}  \PY{c+c1}{\PYZsh{} it is library for scientific computing in Python. I need it becouse it provides a high\PYZhy{}performance }
                              \PY{c+c1}{\PYZsh{} multidimensional array object, and tools for working with these arrays. }
          
          \PY{c+c1}{\PYZsh{} NLP toolbox:}
          
          \PY{c+c1}{\PYZsh{}\PYZsh{} NLTK\PYZhy{} Natural Language Toolkit Python is package that provides a set of natural languages corpora and APIs to an impressing }
          \PY{c+c1}{\PYZsh{}\PYZsh{} diversity of NLP algorithms. }
          
          \PY{k+kn}{import} \PY{n+nn}{nltk} \PY{c+c1}{\PYZsh{} particular moduls will be described when used}
          
          \PY{k+kn}{from} \PY{n+nn}{nltk} \PY{k}{import} \PY{n}{word\PYZus{}tokenize}\PY{p}{,} \PY{n}{pos\PYZus{}tag}\PY{p}{,} \PY{n}{pos\PYZus{}tag\PYZus{}sents}\PY{p}{,} \PY{n}{WordPunctTokenizer}
          \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{tag} \PY{k}{import} \PY{n}{StanfordNERTagger}
          \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{sentiment}\PY{n+nn}{.}\PY{n+nn}{vader} \PY{k}{import} \PY{n}{SentimentIntensityAnalyzer} \PY{k}{as} \PY{n}{SIA}
          \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{stem} \PY{k}{import} \PY{n}{WordNetLemmatizer}\PY{p}{,} \PY{n}{SnowballStemmer}
          \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{stem}\PY{n+nn}{.}\PY{n+nn}{porter} \PY{k}{import} \PY{o}{*}
          \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{corpus} \PY{k}{import} \PY{n}{wordnet} \PY{k}{as} \PY{n}{wn}\PY{p}{,} \PY{n}{stopwords}
          
          \PY{c+c1}{\PYZsh{}\PYZsh{} Gensim \PYZhy{}another package for natural language processing which i use later to check term frequency–inverse document frequency}
          \PY{k+kn}{import} \PY{n+nn}{gensim}
          \PY{k+kn}{from} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{simple\PYZus{}preprocess}
          \PY{k+kn}{from} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{parsing}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{STOPWORDS}
          
          \PY{c+c1}{\PYZsh{} Other}
          \PY{k+kn}{import} \PY{n+nn}{datetime}   \PY{c+c1}{\PYZsh{} module which works with dates as date objects}
          \PY{k+kn}{from} \PY{n+nn}{datetime} \PY{k}{import} \PY{n}{timedelta}
          
          \PY{k+kn}{import} \PY{n+nn}{json} \PY{c+c1}{\PYZsh{} JavaScript Object Notation\PYZhy{} a syntax for storing and exchanging data}
          \PY{k+kn}{import} \PY{n+nn}{glob}  \PY{c+c1}{\PYZsh{} enables use of asterix notation in directory listing}
          \PY{k+kn}{from} \PY{n+nn}{ast} \PY{k}{import} \PY{n}{literal\PYZus{}eval} \PY{c+c1}{\PYZsh{} Abstract Syntax Trees\PYZhy{} will be used to format strings}
          
          \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter} \PY{c+c1}{\PYZsh{} A Counter is a container that keeps track of how many times equivalent values are added}
          \PY{k+kn}{from} \PY{n+nn}{itertools} \PY{k}{import} \PY{n}{chain}
          \PY{k+kn}{import} \PY{n+nn}{random}
          \PY{k+kn}{import} \PY{n+nn}{string}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}317}]:} \PY{c+c1}{\PYZsh{} Downloads neccesary NLTK packages (tools, corpora and tagged dictionaires) in case they are not installed already}
          
          \PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vader\PYZus{}lexicon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}  
          \PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{punkt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{averaged\PYZus{}perceptron\PYZus{}tagger}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} 
          \PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{maxent\PYZus{}ne\PYZus{}chunker}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{words}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wordnet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{nltk}\PY{o}{.}\PY{n}{download\PYZus{}shell}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[nltk\_data] Downloading package vader\_lexicon to
[nltk\_data]     C:\textbackslash{}Users\textbackslash{}Magda\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}nltk\_data{\ldots}
[nltk\_data]   Package vader\_lexicon is already up-to-date!
[nltk\_data] Downloading package punkt to
[nltk\_data]     C:\textbackslash{}Users\textbackslash{}Magda\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}nltk\_data{\ldots}
[nltk\_data]   Package punkt is already up-to-date!
[nltk\_data] Downloading package averaged\_perceptron\_tagger to
[nltk\_data]     C:\textbackslash{}Users\textbackslash{}Magda\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}nltk\_data{\ldots}
[nltk\_data]   Package averaged\_perceptron\_tagger is already up-to-
[nltk\_data]       date!
[nltk\_data] Downloading package maxent\_ne\_chunker to
[nltk\_data]     C:\textbackslash{}Users\textbackslash{}Magda\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}nltk\_data{\ldots}
[nltk\_data]   Package maxent\_ne\_chunker is already up-to-date!
[nltk\_data] Downloading package words to
[nltk\_data]     C:\textbackslash{}Users\textbackslash{}Magda\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}nltk\_data{\ldots}
[nltk\_data]   Package words is already up-to-date!
[nltk\_data] Downloading package wordnet to
[nltk\_data]     C:\textbackslash{}Users\textbackslash{}Magda\textbackslash{}AppData\textbackslash{}Roaming\textbackslash{}nltk\_data{\ldots}
[nltk\_data]   Package wordnet is already up-to-date!

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}317}]:} True
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}411}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
          \PY{k+kn}{from} \PY{n+nn}{pywaffle} \PY{k}{import} \PY{n}{Waffle}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}318}]:} \PY{c+c1}{\PYZsh{} Visualization tools}
          
          \PY{c+c1}{\PYZsh{}\PYZsh{} Seaborn \PYZhy{}will add styles to the matplotlib graphs}
          \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
          
          \PY{c+c1}{\PYZsh{}\PYZsh{} Plotly \PYZhy{}python library which let create graphs}
          \PY{k+kn}{import} \PY{n+nn}{plotly}
          \PY{k+kn}{import} \PY{n+nn}{plotly}\PY{n+nn}{.}\PY{n+nn}{plotly} \PY{k}{as} \PY{n+nn}{py}
          \PY{k+kn}{import} \PY{n+nn}{plotly}\PY{n+nn}{.}\PY{n+nn}{graph\PYZus{}objs} \PY{k}{as} \PY{n+nn}{go}
          \PY{k+kn}{from} \PY{n+nn}{plotly}\PY{n+nn}{.}\PY{n+nn}{offline} \PY{k}{import} \PY{n}{download\PYZus{}plotlyjs}\PY{p}{,} \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{,} \PY{n}{plot}\PY{p}{,} \PY{n}{iplot}
          
          \PY{n}{plotly}\PY{o}{.}\PY{n}{offline}\PY{o}{.}\PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{n}{connected}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Plotly packages initiated locally}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    
    
    \begin{Verbatim}[commandchars=\\\{\}]
Plotly packages initiated locally

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}319}]:} \PY{c+c1}{\PYZsh{} Disable here a warning on deprecated chained assignments}
          
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{mode}\PY{o}{.}\PY{n}{chained\PYZus{}assignment} \PY{o}{=} \PY{k+kc}{None}
\end{Verbatim}


    \subsection{Reading dataset}\label{reading-dataset}

On the begging of analysis there has to be define dataset which will be
analysed. I am going to use created by myself dataset with tweets from
top 26 Silicon Valley (SV) influencers which was saved as csv file named
dataset-sv-201808.csv

    \subsubsection{From a CSV file}\label{from-a-csv-file}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}320}]:} \PY{n}{dataset} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset/dataset\PYZhy{}sv\PYZhy{}201808.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{encoding} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{utf8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                                \PY{n}{dtype}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{favorite\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{retweet\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hashtags\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{symbols\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}mentions\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{urls\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{p}{\PYZcb{}}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} I am using here pandas to read the csv file to create a Python object with rows and columns called data frame }
          \PY{c+c1}{\PYZsh{} that looks very similar to table in a statistical software }
          
          \PY{c+c1}{\PYZsh{} dtype change defined columns into integers }
          
          
          \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Successfully read }\PY{l+s+s1}{\PYZob{}}\PY{l+s+s1}{len(dataset)\PYZcb{} rows of data with }\PY{l+s+s1}{\PYZob{}}\PY{l+s+s1}{len(dataset.columns)\PYZcb{} columns}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}320}]:} 'Successfully read 15367 rows of data with 29 columns'
\end{Verbatim}
            
    \subsubsection{First glance at data}\label{first-glance-at-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}321}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{} here we can see first five (automaticly chosen number) rows for our dataset }
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}321}]:}   screen\_name                   id           created\_at  \textbackslash{}
          0      cdixon  1038564797309177857  2018-09-08 23:08:37   
          1      cdixon  1037739767272808449  2018-09-06 16:30:15   
          2      cdixon  1034830369025974272  2018-08-29 15:49:20   
          3      cdixon  1032404207339356162  2018-08-22 23:08:38   
          4      cdixon  1025251680466558976  2018-08-03 05:27:03   
          
                                                          text  geo place  \textbackslash{}
          0  b'Really enjoyed this discussion with @stevenb{\ldots}  NaN   NaN   
          1  b'Excited to welcome Dan Boneh to the a16z cry{\ldots}  NaN   NaN   
          2  b'RT @ali01: Decentralized networks like DFINI{\ldots}  NaN   NaN   
          3  b'RT @bhorowitz: I am very excited to announce{\ldots}  NaN   NaN   
          4  b'Woz and Jobs at Apple, 1977. https://t.co/Ac{\ldots}  NaN   NaN   
          
             is\_quote\_status  has\_hashtags  has\_symbols  has\_user\_mentions  \textbackslash{}
          0            False         False        False               True   
          1            False         False        False              False   
          2            False         False        False               True   
          3            False         False        False               True   
          4            False         False        False              False   
          
                  {\ldots}         favorited  retweeted  lang  in\_reply\_to\_status\_id  \textbackslash{}
          0       {\ldots}             False      False    en                    NaN   
          1       {\ldots}             False      False    en                    NaN   
          2       {\ldots}             False      False    en                    NaN   
          3       {\ldots}             False      False    en                    NaN   
          4       {\ldots}             False      False    en                    NaN   
          
             in\_reply\_to\_status\_id\_str in\_reply\_to\_user\_id  in\_reply\_to\_user\_id\_str  \textbackslash{}
          0                        NaN                 NaN                      NaN   
          1                        NaN                 NaN                      NaN   
          2                        NaN                 NaN                      NaN   
          3                        NaN                 NaN                      NaN   
          4                        NaN                 NaN                      NaN   
          
             in\_reply\_to\_screen\_name  delta\_followers  followers\_count  
          0                      NaN             -4.0         576650.0  
          1                      NaN             26.0         576726.0  
          2                      NaN             19.0         576516.0  
          3                      NaN             11.0         576411.0  
          4                      NaN              NaN              NaN  
          
          [5 rows x 29 columns]
\end{Verbatim}
            
    \subsubsection{Check the data types}\label{check-the-data-types}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}322}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{columns}\PY{o}{.}\PY{n}{to\PYZus{}series}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{dataset}\PY{o}{.}\PY{n}{dtypes}\PY{p}{)}\PY{o}{.}\PY{n}{groups}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}322}]:} \{dtype('bool'): Index(['is\_quote\_status', 'has\_hashtags', 'has\_symbols', 'has\_user\_mentions',
                  'has\_urls', 'favorited', 'retweeted'],
                 dtype='object'),
           dtype('int64'): Index(['id', 'hashtags\_count', 'symbols\_count', 'user\_mentions\_count',
                  'urls\_count', 'retweet\_count', 'favorite\_count'],
                 dtype='object'),
           dtype('float64'): Index(['contributors', 'in\_reply\_to\_status\_id', 'in\_reply\_to\_status\_id\_str',
                  'in\_reply\_to\_user\_id', 'in\_reply\_to\_user\_id\_str', 'delta\_followers',
                  'followers\_count'],
                 dtype='object'),
           dtype('O'): Index(['screen\_name', 'created\_at', 'text', 'geo', 'place', 'coordinates',
                  'lang', 'in\_reply\_to\_screen\_name'],
                 dtype='object')\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}323}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{created\PYZus{}at}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{to\PYZus{}datetime}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{created\PYZus{}at}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                                                 \PY{n}{errors}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{coerce}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} ensures pandas that this column has datetimes only}
          \PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{n}{dataset}\PY{o}{.}\PY{n}{created\PYZus{}at}\PY{o}{.}\PY{n}{dt}\PY{o}{.}\PY{n}{year} \PY{o}{==} \PY{l+m+mi}{2018}\PY{p}{]}
\end{Verbatim}


    \subsection{Data cleaning}\label{data-cleaning}

    \subsubsection{Get list of columns}\label{get-list-of-columns}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}324}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{columns} \PY{c+c1}{\PYZsh{} we can see the list of columns of our dataset}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}324}]:} Index(['screen\_name', 'id', 'created\_at', 'text', 'geo', 'place',
                 'is\_quote\_status', 'has\_hashtags', 'has\_symbols', 'has\_user\_mentions',
                 'has\_urls', 'hashtags\_count', 'symbols\_count', 'user\_mentions\_count',
                 'urls\_count', 'coordinates', 'contributors', 'retweet\_count',
                 'favorite\_count', 'favorited', 'retweeted', 'lang',
                 'in\_reply\_to\_status\_id', 'in\_reply\_to\_status\_id\_str',
                 'in\_reply\_to\_user\_id', 'in\_reply\_to\_user\_id\_str',
                 'in\_reply\_to\_screen\_name', 'delta\_followers', 'followers\_count'],
                dtype='object')
\end{Verbatim}
            
    \subsubsection{String formatting}\label{string-formatting}

    there is b' on the begging of string what means they are byte-string.
This code will get rid of it

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}325}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{literal\PYZus{}eval}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{.}\PY{n}{decode}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{utf\PYZhy{}8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Check again first rows}\label{check-again-first-rows}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}326}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}326}]:}   screen\_name                   id          created\_at  \textbackslash{}
          0      cdixon  1038564797309177857 2018-09-08 23:08:37   
          1      cdixon  1037739767272808449 2018-09-06 16:30:15   
          2      cdixon  1034830369025974272 2018-08-29 15:49:20   
          3      cdixon  1032404207339356162 2018-08-22 23:08:38   
          4      cdixon  1025251680466558976 2018-08-03 05:27:03   
          
                                                          text  geo place  \textbackslash{}
          0  Really enjoyed this discussion with @stevenbjo{\ldots}  NaN   NaN   
          1  Excited to welcome Dan Boneh to the a16z crypt{\ldots}  NaN   NaN   
          2  RT @ali01: Decentralized networks like DFINITY{\ldots}  NaN   NaN   
          3  RT @bhorowitz: I am very excited to announce T{\ldots}  NaN   NaN   
          4  Woz and Jobs at Apple, 1977. https://t.co/AcLV{\ldots}  NaN   NaN   
          
             is\_quote\_status  has\_hashtags  has\_symbols  has\_user\_mentions  \textbackslash{}
          0            False         False        False               True   
          1            False         False        False              False   
          2            False         False        False               True   
          3            False         False        False               True   
          4            False         False        False              False   
          
                  {\ldots}         favorited  retweeted  lang  in\_reply\_to\_status\_id  \textbackslash{}
          0       {\ldots}             False      False    en                    NaN   
          1       {\ldots}             False      False    en                    NaN   
          2       {\ldots}             False      False    en                    NaN   
          3       {\ldots}             False      False    en                    NaN   
          4       {\ldots}             False      False    en                    NaN   
          
             in\_reply\_to\_status\_id\_str in\_reply\_to\_user\_id  in\_reply\_to\_user\_id\_str  \textbackslash{}
          0                        NaN                 NaN                      NaN   
          1                        NaN                 NaN                      NaN   
          2                        NaN                 NaN                      NaN   
          3                        NaN                 NaN                      NaN   
          4                        NaN                 NaN                      NaN   
          
             in\_reply\_to\_screen\_name  delta\_followers  followers\_count  
          0                      NaN             -4.0         576650.0  
          1                      NaN             26.0         576726.0  
          2                      NaN             19.0         576516.0  
          3                      NaN             11.0         576411.0  
          4                      NaN              NaN              NaN  
          
          [5 rows x 29 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}327}]:} \PY{n}{raw\PYZus{}tweets} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \subsubsection{See raw content of
tweets}\label{see-raw-content-of-tweets}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}328}]:} \PY{n}{raw\PYZus{}tweets}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]} \PY{c+c1}{\PYZsh{} first 10 teets of dataset}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}328}]:} ['Really enjoyed this discussion with @stevenbjohnson about his new book, Farsighted. "a16z Podcast: Seeing into the Future — Making Decisions, Telling Stories" https://t.co/qQixJ1yvaX',
           'Excited to welcome Dan Boneh to the a16z crypto team https://t.co/zHqg2RBw0B',
           'RT @ali01: Decentralized networks like DFINITY stand to bring us closer to a world where digital platforms can be constructed from trustles…',
           'RT @bhorowitz: I am very excited to announce The Cultural Leadership Fund. https://t.co/XuhyRWT6Ky Thank you to @ChrisLyons for leading thi…',
           'Woz and Jobs at Apple, 1977. https://t.co/AcLV5PRoQw',
           'RT @smc90: I asked the brilliant @devonzuegel to guest host some a16z crypto videos with @cdixon, @ali01, @jessewldn @Iiterature, now live…',
           'a16z podcast: Elad Gil and I discuss topics from his excellent new book High Growth Handbook. https://t.co/Uj9jYZuWgt https://t.co/Y9SXHubhkg',
           'RT @bhorowitz: I know our new General Partner is going to be great, because she is @conniechan https://t.co/JYD9Ylz17W',
           'RT @dawnsongtweets: Really excited to start this journey with our community, building a privacy-first, high-performance cloud computing pla…',
           'RT @bhorowitz: I am ridiculously excited about our newest GP, @katie\_haun https://t.co/4kXaRWp1xF']
\end{Verbatim}
            
    \subsubsection{Point which columns are
categorical}\label{point-which-columns-are-categorical}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in\PYZus{}reply\PYZus{}to\PYZus{}status\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in\PYZus{}reply\PYZus{}to\PYZus{}status\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{category}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in\PYZus{}reply\PYZus{}to\PYZus{}status\PYZus{}id\PYZus{}str}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in\PYZus{}reply\PYZus{}to\PYZus{}status\PYZus{}id\PYZus{}str}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{category}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in\PYZus{}reply\PYZus{}to\PYZus{}user\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in\PYZus{}reply\PYZus{}to\PYZus{}user\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{category}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in\PYZus{}reply\PYZus{}to\PYZus{}user\PYZus{}id\PYZus{}str}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in\PYZus{}reply\PYZus{}to\PYZus{}user\PYZus{}id\PYZus{}str}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{category}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \texttt{.astype} is a Pandas method for converting (casting) data type
of a column to another type. I used it here to convert ID's columns to
categorical columns.

The purope of it is to give a signal to other Python libraries that this
column should be treated as a categorical variable

\texttt{Categoricals} are a pandas data type which takes on a limited,
and usually fixed, number of possible values

    \subsubsection{checking if there is a
geolocation}\label{checking-if-there-is-a-geolocation}

If there would be some geocordinates, then I could use them in sentiment
analyses to check wether they impact Tweets contents (e.g. their
sentiment, length, etc.).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}330}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{geo}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}330}]:} \{'type': 'Point', 'coordinates': [43.6031, -111.112]\}            2
          \{'type': 'Point', 'coordinates': [50.04836044, 8.57119149]\}      1
          \{'type': 'Point', 'coordinates': [43.757919, -110.958775]\}       1
          \{'type': 'Point', 'coordinates': [36.08177993, -115.1727134]\}    1
          Name: geo, dtype: int64
\end{Verbatim}
            
    There are almost no geolocation points in our dataset, so I am removing
these columns as I can't get from this column any valuable information

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}331}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{geo}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{coordinates}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}  
\end{Verbatim}


    \subsection{Fill-in missing data}\label{fill-in-missing-data}

Now i am checking if there is any \texttt{NaN\textquotesingle{}s}* in
dataset. I should check it becouse nan's are sometimes generated by
Twitter API, yet they normally represent zero in numeric features

*\texttt{NaN} is a pythonic keyword for null (lack of data)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}332}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{any}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}332}]:} True
\end{Verbatim}
            
    Becouse the result was positive then i am checking which column contains
at least one NaN value- and create list of those columns

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}333}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{dataset}\PY{o}{.}\PY{n}{isna}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{any}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}333}]:} ['place',
           'contributors',
           'in\_reply\_to\_status\_id',
           'in\_reply\_to\_status\_id\_str',
           'in\_reply\_to\_user\_id',
           'in\_reply\_to\_user\_id\_str',
           'in\_reply\_to\_screen\_name',
           'delta\_followers',
           'followers\_count']
\end{Verbatim}
            
    Most of NaN values are in categorical fields which hold information
whether tweet was a response to other tweet/user. In example, if there
is NaN in the column \texttt{in\_reply\_to\_status\_id}, then such
particular tweet wasn't a response to other tweet.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}334}]:} \PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{n}{pd}\PY{o}{.}\PY{n}{isna}\PY{p}{(}\PY{n}{dataset}\PY{o}{.}\PY{n}{followers\PYZus{}count}\PY{p}{)}\PY{p}{]}\PY{o}{.}\PY{n}{index}\PY{p}{)}
          \PY{n}{dataset}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}335}]:} \PY{n}{raw\PYZus{}tweets} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    raw\_tweets will be used later for some nlp preprocessing holds raw
tweets (in order)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}336}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{delta\PYZus{}followers}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{delta\PYZus{}followers}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{followers\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{followers\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Time range}\label{time-range}

to decribe what is the time range i took into analyse.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}337}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Earliest date is }\PY{l+s+s1}{\PYZob{}}\PY{l+s+s1}{dataset.created\PYZus{}at.min()\PYZcb{} and last date is }\PY{l+s+s1}{\PYZob{}}\PY{l+s+s1}{dataset.created\PYZus{}at.max()\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Earliest date is 2018-08-02 05:46:01 and last date is 2018-09-08 23:45:48

    \end{Verbatim}

    \subsubsection{Multivariate analysis}\label{multivariate-analysis}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}338}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{retweet\PYZus{}count\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{retweet\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{x}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
          \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{favorite\PYZus{}count\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{favorite\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{x}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    here i am using log-transformation. It is helpful when dealing with
highy skewed data. using log-transformation makes paterns more visible

    \paragraph{Re-tweets}\label{re-tweets}

    I am counting here how many times particular group of tweets has been
re-tweet.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}339}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{retweet\PYZus{}count\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}339}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x1aade07bb00>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_50_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Description of the chart: \texttt{X-axis} holds log-transformed range of
datapoints in retweet\_count (called 'bin') \texttt{Y-axis} holds counts
of a particular bin

    \paragraph{Conclusions of this
histogram:}\label{conclusions-of-this-histogram}

\begin{verbatim}
- Retweet count on a histogram can be characterized as a typical numeric statistic found in social networks - it has 
long tail, many values in first bin and little values in last bins
- There is a small cluster of mediocre tweets - tweets having between 10^2 and 10^3 retweets
\end{verbatim}

    \paragraph{Tweet likes}\label{tweet-likes}

    I am counting here how many times particular tweet has been 'liked'
('marked as favorite')

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}340}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{favorite\PYZus{}count\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} We characterized the Favorite count on a histogram as a typical numeric statistic }
          \PY{c+c1}{\PYZsh{} found in social networks \PYZhy{} it has long tail, many values in first bin and little values in last bins}
          \PY{c+c1}{\PYZsh{} There is a small cluster of mediocre tweets \PYZhy{} tweets having between 10\PYZca{}3 and 10\PYZca{}4 likes}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}340}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x1aade0cabe0>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_55_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Description of the chart: \texttt{X-axis} holds log-transformed range of
datapoints in favorite\_count (called 'bin') \texttt{Y-axis} holds
counts of a particular bin

    \paragraph{Conclusions of this
histogram:}\label{conclusions-of-this-histogram}

\begin{verbatim}
- Favourite count on a histogram can be characterized as a typical numeric statistic found in social networks - it has 
 long tail, many values in first bin and little values in last bins
- There is a small cluster of mediocre tweets - tweets having between 10^3 and 10^4 retweets
\end{verbatim}

    \paragraph{Most and least popular}\label{most-and-least-popular}

    here i show analyzed accounts in order of popularity (by number of
likes)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}341}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{screen\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{favorite\PYZus{}count}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}341}]:} screen\_name
          elonmusk           1487893
          mkbhd              1197538
          billgates           315970
          tim\_cook            154916
          SwiftonSecurity     106326
          JonErlichman         51643
          KaraSwisher          39960
          dhh                  37996
          benedictevans        37206
          DigitalTrends        32473
          MikeIsaac            24926
          sirajraval           20283
          mims                 13434
          sundarpichai         10406
          BoredElonMusk        10241
          ajitpaifcc            5344
          reshmasaujani         3568
          charlesarthur         3100
          jeffweiner            2892
          asymco                2389
          ericjackson           1694
          emilychangtv           556
          cdixon                 486
          davidcohen             135
          Name: favorite\_count, dtype: int64
\end{Verbatim}
            
    Here by using visualisation tool i am ilustrating dependence of some
factors of tweets to eachother

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}342}]:} \PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hashtags\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}mentions\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{screen\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                     \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{retweet\PYZus{}count\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{favorite\PYZus{}count\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
          
          \PY{n}{sns}\PY{o}{.}\PY{n}{pairplot}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{n}{dataset}\PY{o}{.}\PY{n}{screen\PYZus{}name}\PY{o}{.}\PY{n}{isin}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{elonmusk}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{emilychangtv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{]}\PY{p}{[}\PY{n}{columns}\PY{p}{]}\PY{p}{,} \PY{n}{hue}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}342}]:} <seaborn.axisgrid.PairGrid at 0x1aadd70c2e8>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_62_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    OBSERVATIONS: (based on analyzed the most and least liked accounts)

There are some insights and visible differences between popular and less
popular accounts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \emph{effect of scale} - more \texttt{retweets} means more
  \texttt{likes}, this could be due to dual feedback between those 2
\item
  there is an odd group of tweets which are little liked
  (\texttt{favorite\_count\_log}) but have a significant amount of
  retweets (\texttt{retweet\_count\_log})
\item
  histogram of a \texttt{retweet\_count} is wider for more popular
  accounts
\item
  \texttt{favorite\_count} has a "W" shape
\item
  \texttt{user\_mentioins\_count} is quite similar for both types of
  accounts
\end{enumerate}

    \paragraph{Below i am showing the result of arithmetic avarage of
analyzed
accounts:}\label{below-i-am-showing-the-result-of-arithmetic-avarage-of-analyzed-accounts}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}343}]:} \PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{favorite\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{favorite\PYZus{}count\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{retweet\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  
                     \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{retweet\PYZus{}count\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}mentions\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
          \PY{n}{dataset}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{screen\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{n}{columns}\PY{p}{]}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}343}]:} favorite\_count         2051.895719
          favorite\_count\_log        3.317815
          retweet\_count          1436.846069
          retweet\_count\_log         3.165507
          user\_mentions\_count       1.026472
          dtype: float64
\end{Verbatim}
            
    \subsection{NLP}\label{nlp}

    \subsubsection{Sentiment analysis}\label{sentiment-analysis}

    I use \texttt{SIA} method from the
\texttt{NLTK\textquotesingle{}s\ vader} library

\texttt{NLTK\textquotesingle{}s\ vader\ analyzer} computationally
identifies and categorizes text into three sentiments: positive,
negative, or neutral using a lexicon of positive and negative words.
Sentiment is calculated as a numeric result in range of
\texttt{{[}0.0,\ 1.0)}, where \texttt{1.0} means highest in a particular
dimension. "Neg" abbr. means negative sentiment, "pos" means positive
sentiment, "compound" means general sentiment.

I'll append each sentiment dictionary to a results list, which I'll
transform into a dataframe

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}344}]:} \PY{n}{sia} \PY{o}{=} \PY{n}{SIA}\PY{p}{(}\PY{p}{)}
          \PY{n}{results} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          
          \PY{k}{for} \PY{n}{line} \PY{o+ow}{in} \PY{n}{raw\PYZus{}tweets}\PY{p}{:}
              \PY{n}{pol\PYZus{}score} \PY{o}{=} \PY{n}{sia}\PY{o}{.}\PY{n}{polarity\PYZus{}scores}\PY{p}{(}\PY{n}{line}\PY{p}{)}
              \PY{n}{results}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{pol\PYZus{}score}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}345}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sen\PYZhy{}tagged }\PY{l+s+s1}{\PYZob{}}\PY{l+s+s1}{len(results)\PYZcb{} rows}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{results}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
sen-tagged 11674 rows

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}345}]:} [\{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.6597\},
           \{'neg': 0.0, 'neu': 0.889, 'pos': 0.111, 'compound': 0.3612\},
           \{'neg': 0.0, 'neu': 0.766, 'pos': 0.234, 'compound': 0.6361\},
           \{'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.7906\},
           \{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0\},
           \{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.4404\},
           \{'neg': 0.113, 'neu': 0.887, 'pos': 0.0, 'compound': -0.3182\},
           \{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0\},
           \{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0\}]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}346}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sentiment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{x}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{compound}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{results}\PY{p}{]}\PY{p}{)}
          \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neg\PYZus{}sentiment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{x}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{results}\PY{p}{]}\PY{p}{)}
          \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neu\PYZus{}sentiment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{x}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{results}\PY{p}{]}\PY{p}{)}
          \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pos\PYZus{}sentiment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{x}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{results}\PY{p}{]}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Creates four new columns in the dataset (pandas dataframe) with seperate type of sentiment}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}403}]:} \PY{n}{sent\PYZus{}columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neg\PYZus{}sentiment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neu\PYZus{}sentiment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  
                     \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pos\PYZus{}sentiment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
          \PY{n}{dataset}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{screen\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{n}{sent\PYZus{}columns}\PY{p}{]}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}403}]:} neg\_sentiment    0.036464
          neu\_sentiment    0.822195
          pos\_sentiment    0.141336
          dtype: float64
\end{Verbatim}
            
    Conclusions: - most of tweets have neutral sentiment - negative
sentiment is the rarest

    \paragraph{On the list below i show who has the most positive
tweets:}\label{on-the-list-below-i-show-who-has-the-most-positive-tweets}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}404}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{screen\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{pos\PYZus{}sentiment}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}404}]:} screen\_name
          KaraSwisher        315.111
          DigitalTrends      215.621
          charlesarthur      142.718
          mims               134.183
          SwiftonSecurity    118.970
          benedictevans      101.652
          ericjackson         64.116
          ajitpaifcc          61.944
          dhh                 49.034
          MikeIsaac           45.225
          sirajraval          42.977
          mkbhd               27.800
          asymco              24.311
          reshmasaujani       17.125
          elonmusk            16.267
          billgates            5.590
          JonErlichman         3.774
          davidcohen           3.487
          tim\_cook             2.957
          jeffweiner           1.950
          emilychangtv         1.825
          cdixon               0.866
          sundarpichai         0.829
          BoredElonMusk        0.128
          Name: pos\_sentiment, dtype: float64
\end{Verbatim}
            
    conculsion- The most positive tweets write KaraSwisher

    \paragraph{On the list below i show who has the most negative
tweets:}\label{on-the-list-below-i-show-who-has-the-most-negative-tweets}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}396}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{screen\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{neg\PYZus{}sentiment}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}396}]:} screen\_name
          KaraSwisher        127.917
          charlesarthur       81.889
          benedictevans       79.060
          SwiftonSecurity     77.466
          DigitalTrends       71.938
          mims                48.621
          MikeIsaac           30.572
          ajitpaifcc          26.475
          dhh                 24.735
          ericjackson         18.719
          asymco              10.329
          mkbhd                7.431
          sirajraval           6.977
          elonmusk             5.236
          reshmasaujani        4.480
          billgates            0.909
          emilychangtv         0.667
          JonErlichman         0.436
          jeffweiner           0.241
          tim\_cook             0.122
          cdixon               0.000
          sundarpichai         0.000
          davidcohen           0.000
          BoredElonMusk        0.000
          Name: neg\_sentiment, dtype: float64
\end{Verbatim}
            
    Conclusion- what is interesting also the most number of negative tweets
are realised by KaraSwisher.

    \subsubsection{POS tagger}\label{pos-tagger}

    POS (Parts-Of-Speech) tagging is the process of marking up a word in a
text as corresponding to a particular part of speech,based on both its
definition and its context---i.e., its relationship with adjacent and
related words in a phrase, sentence, or paragraph. A simplified form of
this is commonly taught to school-age children, in the identification of
words as nouns, verbs, adjectives, adverbs, etc.

I parse parts-of-speech here using \texttt{nltk} to describe more basic
characteristics of tweet's text - it's richness in adjectives, number of
nouns, punctuation marks - it can be associated with high/low emotional
content, personal attributes - how a person constructs sentences, etc.

    \paragraph{Tokenize sentences into list of words (in basic
form)}\label{tokenize-sentences-into-list-of-words-in-basic-form}

    Tokenization is the act of breaking up a sequence of strings into pieces
such as words, keywords, phrases, symbols and other elements called
tokens. Tokens can be individual words, phrases or even whole sentences.
In the process of tokenization, some characters like punctuation marks
are discarded

map - mapping every element of an iterable (i.e. 'list') to a result of
function 'word\_tokenize' proccesing

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}348}]:} \PY{n}{tokens\PYZus{}raw} \PY{o}{=} \PY{n+nb}{map}\PY{p}{(}\PY{n}{word\PYZus{}tokenize}\PY{p}{,} \PY{n}{raw\PYZus{}tweets}\PY{p}{)}
\end{Verbatim}


    result of word\_tokenize is a list of "tokens" - sentence (string) is
seperate into a list of seperate words and interpuncts.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}349}]:} \PY{n}{tokens\PYZus{}list} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{tokens\PYZus{}raw}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}350}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tokenized }\PY{l+s+s1}{\PYZob{}}\PY{l+s+s1}{len(results)\PYZcb{} sentences}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Below sample results of word\PYZus{}tokenize function }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{(prints first row):}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{tokens\PYZus{}list}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
tokenized 11674 sentences
Below sample results of word\_tokenize function 
(prints first row):

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}350}]:} ['Really',
           'enjoyed',
           'this',
           'discussion',
           'with',
           '@',
           'stevenbjohnson',
           'about',
           'his',
           'new',
           'book',
           ',',
           'Farsighted',
           '.',
           '``',
           'a16z',
           'Podcast',
           ':',
           'Seeing',
           'into',
           'the',
           'Future',
           '—',
           'Making',
           'Decisions',
           ',',
           'Telling',
           'Stories',
           "''",
           'https',
           ':',
           '//t.co/qQixJ1yvaX']
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}351}]:} \PY{n}{pos\PYZus{}raw} \PY{o}{=} \PY{n}{pos\PYZus{}tag\PYZus{}sents}\PY{p}{(}\PY{n}{tokens\PYZus{}list}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pos\PYZhy{}tagged }\PY{l+s+s1}{\PYZob{}}\PY{l+s+s1}{len(pos\PYZus{}raw)\PYZcb{} rows}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} The results shows what part of speech is particular word from earlier created token list}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
pos-tagged 11674 rows

    \end{Verbatim}

    \paragraph{See sample result below}\label{see-sample-result-below}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}352}]:} \PY{n}{pos\PYZus{}raw}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
          
          \PY{c+c1}{\PYZsh{} on this website there are explained shortcuts of parts of speech : https://www.sketchengine.eu/penn\PYZhy{}treebank\PYZhy{}tagset/ }
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}352}]:} [('Really', 'RB'),
           ('enjoyed', 'VBN'),
           ('this', 'DT'),
           ('discussion', 'NN'),
           ('with', 'IN'),
           ('@', 'NNP'),
           ('stevenbjohnson', 'NN'),
           ('about', 'IN'),
           ('his', 'PRP\$'),
           ('new', 'JJ'),
           ('book', 'NN'),
           (',', ','),
           ('Farsighted', 'NNP'),
           ('.', '.'),
           ('``', '``'),
           ('a16z', 'JJ'),
           ('Podcast', 'NN'),
           (':', ':'),
           ('Seeing', 'VBG'),
           ('into', 'IN'),
           ('the', 'DT'),
           ('Future', 'NNP'),
           ('—', 'NNP'),
           ('Making', 'NNP'),
           ('Decisions', 'NNP'),
           (',', ','),
           ('Telling', 'VBG'),
           ('Stories', 'NNS'),
           ("''", "''"),
           ('https', 'NN'),
           (':', ':'),
           ('//t.co/qQixJ1yvaX', 'NN')]
\end{Verbatim}
            
    \paragraph{List of all POS tags}\label{list-of-all-pos-tags}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}353}]:} \PY{n}{pos\PYZus{}counts} \PY{o}{=} \PY{p}{[}\PY{n}{Counter}\PY{p}{(}\PY{p}{[}\PY{n}{z}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{k}{for} \PY{n}{z} \PY{o+ow}{in} \PY{n}{x}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{pos\PYZus{}raw}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}354}]:} \PY{n}{pos\PYZus{}counts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
          
          \PY{c+c1}{\PYZsh{} Let\PYZsq{}s look at first tweet and its part of speech:}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}354}]:} Counter(\{'RB': 1,
                   'VBN': 1,
                   'DT': 2,
                   'NN': 6,
                   'IN': 3,
                   'NNP': 6,
                   'PRP\$': 1,
                   'JJ': 2,
                   ',': 2,
                   '.': 1,
                   '``': 1,
                   ':': 2,
                   'VBG': 2,
                   'NNS': 1,
                   "''": 1\})
\end{Verbatim}
            
    It's also interesting to count number of interpunction chars (commas,
etc.)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}355}]:} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{pos\PYZus{}counts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} here on the examplary tweet}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}355}]:} \{'RB': 1,
           'VBN': 1,
           'DT': 2,
           'NN': 6,
           'IN': 3,
           'NNP': 6,
           'PRP\$': 1,
           'JJ': 2,
           ',': 2,
           '.': 1,
           '``': 1,
           ':': 2,
           'VBG': 2,
           'NNS': 1,
           "''": 1\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}356}]:} \PY{n}{all\PYZus{}pos} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{chain}\PY{o}{.}\PY{n}{from\PYZus{}iterable}\PY{p}{(}\PY{p}{[}\PY{n+nb}{list}\PY{p}{(}\PY{n}{pos}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{pos} \PY{o+ow}{in} \PY{n}{pos\PYZus{}counts}\PY{p}{]}\PY{p}{)}\PY{p}{)} 
          
          \PY{c+c1}{\PYZsh{} chain function takes any number of iterables as arguments and “chains” them together}
          
          \PY{n}{all\PYZus{}pos} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{n}{all\PYZus{}pos}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Add results to dataset}\label{add-results-to-dataset}

I'm adding here counts of parts-of-speech (POS) as a single column per
particular POS. Then I am creating new columns which you can see below
(starting from 'interpuncts' and 'MD') They all contain count of
occurences of a particular POS

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}357}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{interpuncts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{0}
          
          \PY{k}{for} \PY{n}{pos\PYZus{}name} \PY{o+ow}{in} \PY{n}{all\PYZus{}pos}\PY{p}{:}
              \PY{k}{if} \PY{n}{pos\PYZus{}name} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{(}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{``}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{:}
                  \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{interpuncts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{interpuncts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{pos\PYZus{}counts}\PY{p}{[}\PY{n}{x}\PY{p}{]}\PY{p}{[}\PY{n}{pos\PYZus{}name}\PY{p}{]} \PYZbs{}
                                                 \PY{k}{if} \PY{n}{pos\PYZus{}name} \PY{o+ow}{in} \PY{n}{pos\PYZus{}counts}\PY{p}{[}\PY{n}{x}\PY{p}{]} \PYZbs{}
                                                 \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}\PY{p}{)}
              \PY{k}{else}\PY{p}{:}
                  \PY{n}{dataset}\PY{p}{[}\PY{n}{pos\PYZus{}name}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{pos\PYZus{}counts}\PY{p}{[}\PY{n}{x}\PY{p}{]}\PY{p}{[}\PY{n}{pos\PYZus{}name}\PY{p}{]} \PYZbs{}
                                                 \PY{k}{if} \PY{n}{pos\PYZus{}name} \PY{o+ow}{in} \PY{n}{pos\PYZus{}counts}\PY{p}{[}\PY{n}{x}\PY{p}{]} \PYZbs{}
                                                 \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}358}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{columns}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}358}]:} Index(['screen\_name', 'id', 'created\_at', 'text', 'place', 'is\_quote\_status',
                 'has\_hashtags', 'has\_symbols', 'has\_user\_mentions', 'has\_urls',
                 'hashtags\_count', 'symbols\_count', 'user\_mentions\_count', 'urls\_count',
                 'contributors', 'retweet\_count', 'favorite\_count', 'favorited',
                 'retweeted', 'lang', 'in\_reply\_to\_status\_id',
                 'in\_reply\_to\_status\_id\_str', 'in\_reply\_to\_user\_id',
                 'in\_reply\_to\_user\_id\_str', 'in\_reply\_to\_screen\_name', 'delta\_followers',
                 'followers\_count', 'retweet\_count\_log', 'favorite\_count\_log',
                 'sentiment', 'neg\_sentiment', 'neu\_sentiment', 'pos\_sentiment',
                 'interpuncts', 'WRB', 'RBR', 'CD', 'DT', 'LS', 'IN', 'VBD', 'NNP',
                 'SYM', 'RB', 'NNS', 'VBP', 'VBN', 'VBZ', 'PRP\$', 'JJ', 'PDT', 'UH',
                 'NNPS', 'RP', 'VBG', 'EX', 'MD', 'NN', 'JJR', 'JJS', 'PRP', 'POS', 'VB',
                 'FW', 'CC', 'WDT', 'TO', 'WP', 'RBS', 'WP\$'],
                dtype='object')
\end{Verbatim}
            
    \paragraph{Here i show how many of particular part of speech includes
dataset:}\label{here-i-show-how-many-of-particular-part-of-speech-includes-dataset}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}406}]:} \PY{n}{pos\PYZus{}columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{interpuncts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WRB}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RBR}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CD}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{IN}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VBD}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NNP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SYM}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RB}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NNS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VBP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VBN}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VBZ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PRP\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PDT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NNPS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VBG}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EX}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MD}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NN}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JJR}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JJS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PRP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{POS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{VB}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{FW}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CC}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WDT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TO}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RBS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WP\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
          \PY{n}{dataset}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{screen\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{n}{pos\PYZus{}columns}\PY{p}{]}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}406}]:} NN             4.474740
          interpuncts    3.384168
          NNP            3.157817
          IN             1.965039
          JJ             1.812004
          DT             1.493433
          NNS            1.060055
          PRP            0.946418
          VB             0.886940
          RB             0.819244
          CD             0.717962
          VBZ            0.631470
          TO             0.611760
          VBP            0.607492
          CC             0.529720
          VBG            0.485957
          PRP\$           0.373768
          VBD            0.359510
          VBN            0.291207
          MD             0.198512
          WRB            0.134945
          JJR            0.103977
          WDT            0.093447
          WP             0.092143
          JJS            0.077340
          RP             0.074776
          POS            0.063788
          RBR            0.036339
          NNPS           0.026527
          EX             0.019335
          PDT            0.016037
          UH             0.012962
          FW             0.011823
          RBS            0.007492
          SYM            0.000938
          WP\$            0.000724
          LS             0.000035
          dtype: float64
\end{Verbatim}
            
    Conclusions: - the most used POS is \texttt{NN} (noun, singular or mass,
not specific) \texttt{interpuncts} and \texttt{NNP}(Proper nouns, name
specific people, places, things, or ideas)

    \subsubsection{NER tagger}\label{ner-tagger}

    NER (Named-Entities Recognition)- is about locating and classifying
named entities in texts in order to recognize places, people, dates,
values, organizations.

    I am tagging below words from tweets by their named entity (one of:
\texttt{facility/building} (\texttt{facility}), \texttt{geopolitical}
(\texttt{gpe}, \texttt{gsp}), \texttt{location}, \texttt{organization}
or \texttt{person}). Next, I am counting occurences of named entitites
per tweet and add those counts to the \texttt{dataset}.

    \paragraph{NLTK's named entity
recognizer}\label{nltks-named-entity-recognizer}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}360}]:} \PY{n}{ner\PYZus{}set} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{)}
          
          \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n}{tokens\PYZus{}list}\PY{p}{:}
              \PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{ne\PYZus{}chunk}\PY{p}{(}\PY{n}{nltk}\PY{o}{.}\PY{n}{pos\PYZus{}tag}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                  \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{chunk}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                      \PY{n}{ner\PYZus{}set}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{chunk}\PY{o}{.}\PY{n}{label}\PY{p}{(}\PY{p}{)}\PY{p}{)}
                      
          \PY{c+c1}{\PYZsh{} I\PYZsq{}m counting named entities in the tweet text and add those counts as new columns to the dataset}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}413}]:} \PY{n}{dataset}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}organization\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gsp\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}facility\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gpe\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                   \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}person\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}413}]:}        ner\_organization\_count  ner\_gsp\_count  ner\_facility\_count  \textbackslash{}
          count            11674.000000   11674.000000        11674.000000   
          mean                 0.427788       0.007024            0.005054   
          std                  0.677225       0.086541            0.078919   
          min                  0.000000       0.000000            0.000000   
          25\%                  0.000000       0.000000            0.000000   
          50\%                  0.000000       0.000000            0.000000   
          75\%                  1.000000       0.000000            0.000000   
          max                  5.000000       2.000000            4.000000   
          
                 ner\_gpe\_count  ner\_person\_count  
          count   11674.000000      11674.000000  
          mean        0.184427          0.397807  
          std         0.486776          0.719363  
          min         0.000000          0.000000  
          25\%         0.000000          0.000000  
          50\%         0.000000          0.000000  
          75\%         0.000000          1.000000  
          max        10.000000          8.000000  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}361}]:} \PY{n}{ner\PYZus{}set}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}361}]:} \{'FACILITY', 'GPE', 'GSP', 'LOCATION', 'ORGANIZATION', 'PERSON'\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}362}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}person\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n+nb}{sum}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1} \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{chunk}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o+ow}{and} \PY{n}{chunk}\PY{o}{.}\PY{n}{label}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PERSON}\PY{l+s+s1}{\PYZsq{}} 
                                                        \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{ne\PYZus{}chunk}\PY{p}{(}\PY{n}{nltk}\PY{o}{.}\PY{n}{pos\PYZus{}tag}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n}{tokens\PYZus{}list}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}363}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gpe\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n+nb}{sum}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1} \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{chunk}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o+ow}{and} \PY{n}{chunk}\PY{o}{.}\PY{n}{label}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GPE}\PY{l+s+s1}{\PYZsq{}} 
                                                     \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{ne\PYZus{}chunk}\PY{p}{(}\PY{n}{nltk}\PY{o}{.}\PY{n}{pos\PYZus{}tag}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n}{tokens\PYZus{}list}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}364}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}location\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n+nb}{sum}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1} \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{chunk}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o+ow}{and} \PY{n}{chunk}\PY{o}{.}\PY{n}{label}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LOCATION}\PY{l+s+s1}{\PYZsq{}} 
                                                          \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{ne\PYZus{}chunk}\PY{p}{(}\PY{n}{nltk}\PY{o}{.}\PY{n}{pos\PYZus{}tag}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n}{tokens\PYZus{}list}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}365}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}facility\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n+nb}{sum}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1} \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{chunk}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o+ow}{and} \PY{n}{chunk}\PY{o}{.}\PY{n}{label}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{FACILITY}\PY{l+s+s1}{\PYZsq{}} 
                                                          \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{ne\PYZus{}chunk}\PY{p}{(}\PY{n}{nltk}\PY{o}{.}\PY{n}{pos\PYZus{}tag}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n}{tokens\PYZus{}list}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}366}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gsp\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n+nb}{sum}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1} \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{chunk}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o+ow}{and} \PY{n}{chunk}\PY{o}{.}\PY{n}{label}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GSP}\PY{l+s+s1}{\PYZsq{}} 
                                                     \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{ne\PYZus{}chunk}\PY{p}{(}\PY{n}{nltk}\PY{o}{.}\PY{n}{pos\PYZus{}tag}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n}{tokens\PYZus{}list}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}367}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}organization\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n+nb}{sum}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1} \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{chunk}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o+ow}{and} \PY{n}{chunk}\PY{o}{.}\PY{n}{label}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ORGANIZATION}\PY{l+s+s1}{\PYZsq{}} 
                                                              \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{ne\PYZus{}chunk}\PY{p}{(}\PY{n}{nltk}\PY{o}{.}\PY{n}{pos\PYZus{}tag}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)} 
                                                         \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n}{tokens\PYZus{}list}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}368}]:} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}organization\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n+nb}{sum}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1} \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{chunk}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o+ow}{and} \PY{n}{chunk}\PY{o}{.}\PY{n}{label}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ORGANIZATION}\PY{l+s+s1}{\PYZsq{}} 
                                                              \PY{k}{else} \PY{l+m+mi}{0} \PY{k}{for} \PY{n}{chunk} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{ne\PYZus{}chunk}\PY{p}{(}\PY{n}{nltk}\PY{o}{.}\PY{n}{pos\PYZus{}tag}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)} 
                                                         \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n}{tokens\PYZus{}list}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{ner\PYZus{}sum} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}person\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gpe\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}location\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PYZbs{}
                  \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}facility\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gsp\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}organization\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{person\PYZus{}count} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}person\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{ner\PYZus{}sum} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{gpe\PYZus{}count} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gpe\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{ner\PYZus{}sum} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{location\PYZus{}count} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}location\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{ner\PYZus{}sum} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{facility\PYZus{}count} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}facility\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{ner\PYZus{}sum} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{gsp\PYZus{}count} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gsp\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{ner\PYZus{}sum} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{organization\PYZus{}count} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}organization\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{ner\PYZus{}sum} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}
        
        \PY{n}{data} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PERSON}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{person\PYZus{}count}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GPE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{gpe\PYZus{}count}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ORGANIZATION}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{organization\PYZus{}count}\PY{p}{,} 
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{OTHER (gsp, facility \PYZam{} location)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{3}\PY{p}{\PYZcb{}}
\end{Verbatim}


    Here I am using pandas calculations to make a waffle chart

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}412}]:} \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}
              \PY{n}{FigureClass}\PY{o}{=}\PY{n}{Waffle}\PY{p}{,} 
              \PY{n}{rows}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} 
              \PY{n}{values}\PY{o}{=}\PY{n}{data}\PY{p}{,} 
              \PY{n}{colors}\PY{o}{=}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}983D3D}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}232066}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}DCB732}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,}
              \PY{n}{title}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Distribution of named entities in the whole dataset (all tweets)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{,}
              \PY{n}{labels}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}0\PYZcb{}}\PY{l+s+s2}{ (}\PY{l+s+si}{\PYZob{}1\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{)}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{k}\PY{p}{,} \PY{n}{v}\PY{p}{)} \PY{k}{for} \PY{n}{k}\PY{p}{,} \PY{n}{v} \PY{o+ow}{in} \PY{n}{data}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{,}
              \PY{n}{legend}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lower left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bbox\PYZus{}to\PYZus{}anchor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mf}{0.4}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ncol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{framealpha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{0}\PY{p}{\PYZcb{}}
          \PY{p}{)}
          \PY{n}{fig}\PY{o}{.}\PY{n}{gca}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}facecolor}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}EEEEEE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{fig}\PY{o}{.}\PY{n}{set\PYZus{}facecolor}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}EEEEEE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{fig}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mf}{10.5}\PY{p}{,} \PY{n}{forward}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
          \PY{n}{fig}\PY{o}{.}\PY{n}{set\PYZus{}tight\PYZus{}layout}\PY{p}{(}\PY{k+kc}{False}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_119_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}408}]:} \PY{n}{ner\PYZus{}columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}organization\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gsp\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}facility\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}gpe\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                   \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}person\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
          \PY{n}{dataset}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{screen\PYZus{}name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{n}{ner\PYZus{}columns}\PY{p}{]}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}408}]:} ner\_organization\_count    0.507443
          ner\_person\_count          0.408387
          ner\_gpe\_count             0.242950
          ner\_facility\_count        0.010082
          ner\_gsp\_count             0.006960
          dtype: float64
\end{Verbatim}
            
    Conclusions: - as is visible on two of used method (chart and numerical
inforamtion) In the dataset the most popular words concerns
organisation, soon after it person related words. Also GPE (Geopolitical
Entity) related words placed relatively high position

    \subsubsection{Tf-Idf vectorizer}\label{tf-idf-vectorizer}

    TFIDF, short for term frequency--inverse document frequency, is a
numerical statistic that is intended to reflect how important a word is
to a document in a collection or corpus. I use Gensim and NLTK to
calculate Tf-idf matrices.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}370}]:} \PY{n}{stemmer} \PY{o}{=} \PY{n}{PorterStemmer}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    here I write a function to perform lemmatize and stem preprocessing
steps on the data set

\texttt{stemming} is an algorithms work by cutting off the end or the
beginning of the word, taking into account a list of common prefixes and
suffixes that can be found in an inflected word

\texttt{lemmatization} is a method of converting the words of a sentence
to its dictionary form

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{lemmatize\PYZus{}stemming}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}     
            \PY{k}{return} \PY{n}{stemmer}\PY{o}{.}\PY{n}{stem}\PY{p}{(}\PY{n}{WordNetLemmatizer}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{lemmatize}\PY{p}{(}\PY{n}{text}\PY{p}{,} \PY{n}{pos}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{v}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{custom\PYZus{}stop\PYZus{}w} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{http}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{https}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.com}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}   \PY{c+c1}{\PYZsh{} they occur a lot in tweet raw text in form of hyperlinks}
                                                    \PY{c+c1}{\PYZsh{} purpose of this code is the same as of stoplist (stopwords) \PYZhy{} common elements }
                                                    \PY{c+c1}{\PYZsh{} which don\PYZsq{}t add value to text are removed }
        
        \PY{k}{def} \PY{n+nf}{preprocess}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
            \PY{n}{result} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{for} \PY{n}{token} \PY{o+ow}{in} \PY{n}{gensim}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{simple\PYZus{}preprocess}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
                \PY{k}{if} \PY{n}{token} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{gensim}\PY{o}{.}\PY{n}{parsing}\PY{o}{.}\PY{n}{preprocessing}\PY{o}{.}\PY{n}{STOPWORDS} \PY{o+ow}{and} \PY{n+nb}{len}\PY{p}{(}\PY{n}{token}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{3} \PY{o+ow}{and} \PY{n}{token} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{custom\PYZus{}stop\PYZus{}w}\PY{p}{:}
                    \PY{n}{result}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{lemmatize\PYZus{}stemming}\PY{p}{(}\PY{n}{token}\PY{p}{)}\PY{p}{)}
            \PY{k}{return} \PY{n}{result}
\end{Verbatim}


    This function contains methods for parsing and preprocessing strings:

\begin{itemize}
\item
  gensim.utils.simple\_preprocess(text)- Convert a document into a list
  of lowercase tokens, ignoring tokens that are too short or too long
\item
  gensim.parsing.preprocessing- preprocess string (in default NLP
  meaning)
\end{itemize}

    I filter out words from tweets which are on the STOPLIST (popular but
having no information characters - \texttt{a}, \texttt{an}, \texttt{the}
et cetera)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}372}]:} \PY{n}{processed\PYZus{}twitts} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{preprocess}\PY{p}{)}
          \PY{n}{processed\PYZus{}twitts}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}372}]:} 0    [enjoy, discuss, stevenbjohnson, book, farsigh{\ldots}
          1           [excit, welcom, boneh, crypto, team, zhqg]
          2    [decentr, network, like, dfiniti, stand, bring{\ldots}
          3    [bhorowitz, excit, announc, cultur, leadership{\ldots}
          4    [claychristensen, special, moment, galley, boo{\ldots}
          5    [natbullard, tour, forc, expect, asymco, dprkj{\ldots}
          6    [asymco, micromobl, attack, present, competit,{\ldots}
          7    [asymco, micromobl, defin, disrupt, second, mi{\ldots}
          8    [haveagomobl, phrase, unbundl, mobil, catch, h{\ldots}
          9    [tommykornmd, see, peopl, everyday, senior, pa{\ldots}
          Name: text, dtype: object
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}373}]:} \PY{n}{dictionary} \PY{o}{=} \PY{n}{gensim}\PY{o}{.}\PY{n}{corpora}\PY{o}{.}\PY{n}{Dictionary}\PY{p}{(}\PY{n}{processed\PYZus{}twitts}\PY{p}{)}
          
          \PY{n}{count} \PY{o}{=} \PY{l+m+mi}{0}
          \PY{k}{for} \PY{n}{k}\PY{p}{,} \PY{n}{v} \PY{o+ow}{in} \PY{n}{dictionary}\PY{o}{.}\PY{n}{iteritems}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{n+nb}{print}\PY{p}{(}\PY{n}{k}\PY{p}{,} \PY{n}{v}\PY{p}{)}
              
              \PY{k}{if} \PY{n}{count} \PY{o}{\PYZgt{}} \PY{l+m+mi}{10}\PY{p}{:}
                  \PY{k}{break}
              \PY{k}{else}\PY{p}{:}
                  \PY{n}{count} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
0 book
1 decis
2 discuss
3 enjoy
4 farsight
5 futur
6 make
7 podcast
8 qqixj
9 see
10 stevenbjohnson
11 stori

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}374}]:} \PY{n}{dictionary}\PY{o}{.}\PY{n}{filter\PYZus{}extremes}\PY{p}{(}\PY{n}{no\PYZus{}below}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{,} \PY{n}{no\PYZus{}above}\PY{o}{=}\PY{l+m+mf}{0.4}\PY{p}{,} \PY{n}{keep\PYZus{}n}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
\end{Verbatim}


    We also take out most popular words by threshold - if word exists in
more than 40\% tweets, we remove it, we also take out words which are
found less than 15 times. We want to have only 1000 words in
\texttt{bag\ of\ words}.

\texttt{Bag\ of\ words} (can be optionally tf-idf transformed, what has
been done here) is a mathematical representation of a text in form of
numeric matric built by counting occurences of words in their basic
form.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}375}]:} \PY{n}{bow\PYZus{}corpus} \PY{o}{=} \PY{p}{[}\PY{n}{dictionary}\PY{o}{.}\PY{n}{doc2bow}\PY{p}{(}\PY{n}{doc}\PY{p}{)} \PY{k}{for} \PY{n}{doc} \PY{o+ow}{in} \PY{n}{processed\PYZus{}twitts}\PY{p}{]}
          \PY{n}{bow\PYZus{}corpus}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}  \PY{c+c1}{\PYZsh{} print first element}
          
          \PY{c+c1}{\PYZsh{} BOW is abbr. for bag of words}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}375}]:} [(0, 1),
           (1, 1),
           (2, 1),
           (3, 1),
           (4, 1),
           (5, 1),
           (6, 1),
           (7, 1),
           (8, 1),
           (9, 1)]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}376}]:} \PY{n}{bow\PYZus{}doc\PYZus{}first} \PY{o}{=} \PY{n}{bow\PYZus{}corpus}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
          
          \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{bow\PYZus{}doc\PYZus{}first}\PY{p}{)}\PY{p}{)}\PY{p}{:}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Word }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ (}\PY{l+s+se}{\PYZbs{}\PYZdq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}\PYZdq{}}\PY{l+s+s2}{) appears }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ time.}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{bow\PYZus{}doc\PYZus{}first}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} 
                                                         \PY{n}{dictionary}\PY{p}{[}\PY{n}{bow\PYZus{}doc\PYZus{}first}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{,} 
          \PY{n}{bow\PYZus{}doc\PYZus{}first}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Word 0 ("book") appears 1 time.
Word 1 ("decis") appears 1 time.
Word 2 ("discuss") appears 1 time.
Word 3 ("enjoy") appears 1 time.
Word 4 ("futur") appears 1 time.
Word 5 ("make") appears 1 time.
Word 6 ("podcast") appears 1 time.
Word 7 ("see") appears 1 time.
Word 8 ("stori") appears 1 time.
Word 9 ("tell") appears 1 time.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}377}]:} \PY{k+kn}{from} \PY{n+nn}{gensim} \PY{k}{import} \PY{n}{corpora}\PY{p}{,} \PY{n}{models}
          
          \PY{n}{tfidf} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{TfidfModel}\PY{p}{(}\PY{n}{bow\PYZus{}corpus}\PY{p}{)}  \PY{c+c1}{\PYZsh{} tf\PYZhy{}idf transform on bag of words matrix}
          \PY{n}{corpus\PYZus{}tfidf} \PY{o}{=} \PY{n}{tfidf}\PY{p}{[}\PY{n}{bow\PYZus{}corpus}\PY{p}{]}
          
          \PY{k+kn}{from} \PY{n+nn}{pprint} \PY{k}{import} \PY{n}{pprint}
          
          \PY{n}{pprint}\PY{p}{(}\PY{n}{corpus\PYZus{}tfidf}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[(0, 0.3144768226931222),
 (1, 0.38748597054977996),
 (2, 0.3322233549173927),
 (3, 0.3587061996063236),
 (4, 0.31696569558112486),
 (5, 0.2572538901631823),
 (6, 0.30198312479333816),
 (7, 0.3144768226931222),
 (8, 0.28881266145519346),
 (9, 0.267894393670518)]

    \end{Verbatim}

    \subsection{Plot some NLP data}\label{plot-some-nlp-data}

    \subsubsection{Case: Elon musk (most popular
account)}\label{case-elon-musk-most-popular-account}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}378}]:} \PY{n}{dataset}\PY{p}{[}\PY{p}{(}\PY{n}{dataset}\PY{o}{.}\PY{n}{screen\PYZus{}name} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{elonmusk}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{dataset}\PY{o}{.}\PY{n}{sentiment} \PY{o}{\PYZlt{}} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{]}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}378}]:}                  id  hashtags\_count  symbols\_count  user\_mentions\_count  \textbackslash{}
          count  2.100000e+01            21.0           21.0            21.000000   
          mean   1.033822e+18             0.0            0.0             1.857143   
          std    2.437707e+15             0.0            0.0             1.492840   
          min    1.028986e+18             0.0            0.0             0.000000   
          25\%    1.032804e+18             0.0            0.0             1.000000   
          50\%    1.033493e+18             0.0            0.0             1.000000   
          75\%    1.034483e+18             0.0            0.0             3.000000   
          max    1.038526e+18             0.0            0.0             5.000000   
          
                 urls\_count  contributors  retweet\_count  favorite\_count  \textbackslash{}
          count   21.000000           0.0      21.000000       21.000000   
          mean     0.190476           NaN    2148.761905    15268.857143   
          std      0.402374           NaN    3183.949888    25272.692111   
          min      0.000000           NaN      35.000000        0.000000   
          25\%      0.000000           NaN     109.000000     1027.000000   
          50\%      0.000000           NaN     616.000000     1640.000000   
          75\%      0.000000           NaN    3946.000000    16431.000000   
          max      1.000000           NaN   13299.000000   100947.000000   
          
                 delta\_followers  followers\_count           {\ldots}                   TO  \textbackslash{}
          count        21.000000     2.100000e+01           {\ldots}            21.000000   
          mean       6850.190476     2.239517e+07           {\ldots}             0.428571   
          std        6014.689540     3.902509e+04           {\ldots}             0.810643   
          min       -4370.000000     2.232461e+07           {\ldots}             0.000000   
          25\%        4998.000000     2.238012e+07           {\ldots}             0.000000   
          50\%        5340.000000     2.238546e+07           {\ldots}             0.000000   
          75\%        6552.000000     2.240543e+07           {\ldots}             1.000000   
          max       29745.000000     2.248343e+07           {\ldots}             3.000000   
          
                   WP   RBS   WP\$  ner\_person\_count  ner\_gpe\_count  ner\_location\_count  \textbackslash{}
          count  21.0  21.0  21.0         21.000000      21.000000                21.0   
          mean    0.0   0.0   0.0          0.619048       0.095238                 0.0   
          std     0.0   0.0   0.0          1.023533       0.300793                 0.0   
          min     0.0   0.0   0.0          0.000000       0.000000                 0.0   
          25\%     0.0   0.0   0.0          0.000000       0.000000                 0.0   
          50\%     0.0   0.0   0.0          0.000000       0.000000                 0.0   
          75\%     0.0   0.0   0.0          1.000000       0.000000                 0.0   
          max     0.0   0.0   0.0          3.000000       1.000000                 0.0   
          
                 ner\_facility\_count  ner\_gsp\_count  ner\_organization\_count  
          count                21.0           21.0               21.000000  
          mean                  0.0            0.0                0.428571  
          std                   0.0            0.0                0.870140  
          min                   0.0            0.0                0.000000  
          25\%                   0.0            0.0                0.000000  
          50\%                   0.0            0.0                0.000000  
          75\%                   0.0            0.0                0.000000  
          max                   0.0            0.0                3.000000  
          
          [8 rows x 59 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}379}]:} \PY{n}{elon} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{n}{dataset}\PY{o}{.}\PY{n}{screen\PYZus{}name} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{elonmusk}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}380}]:} \PY{n}{elon}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{elon}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W}\PY{l+s+s2}{\PYZob{}}\PY{l+s+s2}{x[}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{created\PYZus{}at}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{].isocalendar()[1]\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} here i am adding column with week number}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}86}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ner\PYZus{}person\PYZus{}count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        KeyError                                  Traceback (most recent call last)

        \textasciitilde{}\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}pandas\textbackslash{}core\textbackslash{}indexes\textbackslash{}base.py in get\_loc(self, key, method, tolerance)
       3062             try:
    -> 3063                 return self.\_engine.get\_loc(key)
       3064             except KeyError:
    

        pandas\textbackslash{}\_libs\textbackslash{}index.pyx in pandas.\_libs.index.IndexEngine.get\_loc()
    

        pandas\textbackslash{}\_libs\textbackslash{}index.pyx in pandas.\_libs.index.IndexEngine.get\_loc()
    

        pandas\textbackslash{}\_libs\textbackslash{}hashtable\_class\_helper.pxi in pandas.\_libs.hashtable.PyObjectHashTable.get\_item()
    

        pandas\textbackslash{}\_libs\textbackslash{}hashtable\_class\_helper.pxi in pandas.\_libs.hashtable.PyObjectHashTable.get\_item()
    

        KeyError: 'ner\_person\_count'

        
    During handling of the above exception, another exception occurred:
    

        KeyError                                  Traceback (most recent call last)

        <ipython-input-86-d2fd3869b481> in <module>()
    ----> 1 print(dataset['ner\_person\_count'])
    

        \textasciitilde{}\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}pandas\textbackslash{}core\textbackslash{}frame.py in \_\_getitem\_\_(self, key)
       2683             return self.\_getitem\_multilevel(key)
       2684         else:
    -> 2685             return self.\_getitem\_column(key)
       2686 
       2687     def \_getitem\_column(self, key):
    

        \textasciitilde{}\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}pandas\textbackslash{}core\textbackslash{}frame.py in \_getitem\_column(self, key)
       2690         \# get column
       2691         if self.columns.is\_unique:
    -> 2692             return self.\_get\_item\_cache(key)
       2693 
       2694         \# duplicate columns \& possible reduce dimensionality
    

        \textasciitilde{}\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}pandas\textbackslash{}core\textbackslash{}generic.py in \_get\_item\_cache(self, item)
       2484         res = cache.get(item)
       2485         if res is None:
    -> 2486             values = self.\_data.get(item)
       2487             res = self.\_box\_item\_values(item, values)
       2488             cache[item] = res
    

        \textasciitilde{}\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}pandas\textbackslash{}core\textbackslash{}internals.py in get(self, item, fastpath)
       4113 
       4114             if not isna(item):
    -> 4115                 loc = self.items.get\_loc(item)
       4116             else:
       4117                 indexer = np.arange(len(self.items))[isna(self.items)]
    

        \textasciitilde{}\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}pandas\textbackslash{}core\textbackslash{}indexes\textbackslash{}base.py in get\_loc(self, key, method, tolerance)
       3063                 return self.\_engine.get\_loc(key)
       3064             except KeyError:
    -> 3065                 return self.\_engine.get\_loc(self.\_maybe\_cast\_indexer(key))
       3066 
       3067         indexer = self.get\_indexer([key], method=method, tolerance=tolerance)
    

        pandas\textbackslash{}\_libs\textbackslash{}index.pyx in pandas.\_libs.index.IndexEngine.get\_loc()
    

        pandas\textbackslash{}\_libs\textbackslash{}index.pyx in pandas.\_libs.index.IndexEngine.get\_loc()
    

        pandas\textbackslash{}\_libs\textbackslash{}hashtable\_class\_helper.pxi in pandas.\_libs.hashtable.PyObjectHashTable.get\_item()
    

        pandas\textbackslash{}\_libs\textbackslash{}hashtable\_class\_helper.pxi in pandas.\_libs.hashtable.PyObjectHashTable.get\_item()
    

        KeyError: 'ner\_person\_count'

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}381}]:} \PY{n}{musk\PYZus{}weeks} \PY{o}{=} \PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{musk\PYZus{}weeks}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}381}]:}           mean
          week          
          W32   0.246250
          W33   0.212732
          W34   0.156200
          W35   0.118259
          W36   0.072717
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}382}]:}  \PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W32}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{} example}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}382}]:} [0.0,
           0.9688,
           0.9682,
           0.2382,
           0.5859,
           0.2023,
           0.0,
           0.0,
           0.0,
           0.0,
           0.0,
           0.4588,
           0.0,
           0.0,
           0.0,
           0.0,
           0.0,
           0.6249,
           0.8779,
           0.0]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}383}]:} \PY{n}{traceW32} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W32}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 32}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          \PY{n}{traceW33} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W33}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 33}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          \PY{n}{traceW34} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W34}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 34}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          \PY{n}{traceW35} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W35}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 35}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          \PY{n}{traceW36} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W36}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 36}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          
          \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{traceW32}\PY{p}{,} \PY{n}{traceW33}\PY{p}{,} \PY{n}{traceW34}\PY{p}{,} \PY{n}{traceW35}\PY{p}{,} \PY{n}{traceW36}\PY{p}{]}
          
          \PY{n}{layout} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Layout}\PY{p}{(}
              \PY{n}{title} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Elon Musk}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{s Compound sentiment over weeks}\PY{l+s+s2}{\PYZdq{}}
          \PY{p}{)}
          
          \PY{n}{fig} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Figure}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,}\PY{n}{layout}\PY{o}{=}\PY{n}{layout}\PY{p}{)}
          
          \PY{n}{iplot}\PY{p}{(}\PY{n}{fig}\PY{p}{)}
\end{Verbatim}


    
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}384}]:} \PY{n}{traceW32} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W32}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{neg\PYZus{}sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 32}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          \PY{n}{traceW33} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W33}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{neg\PYZus{}sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 33}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          \PY{n}{traceW34} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W34}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{neg\PYZus{}sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 34}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          \PY{n}{traceW35} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W35}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{neg\PYZus{}sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 35}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          \PY{n}{traceW36} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Box}\PY{p}{(}
              \PY{n}{y}\PY{o}{=}\PY{n}{elon}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{get\PYZus{}group}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{W36}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{neg\PYZus{}sentiment}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,}
              \PY{n}{boxpoints}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Week 36}\PY{l+s+s1}{\PYZsq{}}
          \PY{p}{)}
          
          \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{traceW32}\PY{p}{,} \PY{n}{traceW33}\PY{p}{,} \PY{n}{traceW34}\PY{p}{,} \PY{n}{traceW35}\PY{p}{,} \PY{n}{traceW36}\PY{p}{]}
          
          \PY{n}{layout} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Layout}\PY{p}{(}
              \PY{n}{title} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Elon Musk}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{s negative sentiment over weeks}\PY{l+s+s2}{\PYZdq{}}
          \PY{p}{)}
          
          \PY{n}{fig} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Figure}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,}\PY{n}{layout}\PY{o}{=}\PY{n}{layout}\PY{p}{)}
          
          \PY{n}{iplot}\PY{p}{(}\PY{n}{fig}\PY{p}{)}
\end{Verbatim}


    
    
    Plot shows that some weeks produce more or less negative/positive
content in the tweets, there is also some significant variance in
emotional load in the text. There were weeks without negative tweets
(week 32), and there are some trend from week 34 to week 36.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
